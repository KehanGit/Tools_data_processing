{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from scipy.stats import theilslopes\n",
    "\n",
    "def download_data(variable, years, dir_prism):\n",
    "    dir_ppt = os.path.join(dir_prism, variable+'/annual')\n",
    "    os.makedirs(dir_ppt, exist_ok=True)\n",
    "    for yr in years:\n",
    "        url = 'https://services.nacse.org/prism/data/public/4km/' + variable + '/' + str(yr)\n",
    "        ! wget --content-disposition {url} --directory-prefix {dir_ppt} -q\n",
    "\n",
    "# unzip files \n",
    "def unzip_prism(dir_download):\n",
    "    fn = glob.glob(dir_download + '/*.zip')\n",
    "    for f in fn:\n",
    "        dir_path, zip_file = os.path.split(f)\n",
    "        filename_without_ext = os.path.splitext(zip_file)[0]\n",
    "\n",
    "        out_dir = os.path.join(dir_path, filename_without_ext)\n",
    "        os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "        with ZipFile(f, 'r') as zipfile:\n",
    "            zipfile.extractall(out_dir)\n",
    "            \n",
    "# function used to calculate theilslpes\n",
    "def theil_sen_trend(arr):\n",
    "    x = np.arange(len(arr))\n",
    "    # print(x)\n",
    "    # print(arr)\n",
    "    slopes = theilslopes(arr, x)[0]\n",
    "    # slopes = np.mean(arr)\n",
    "    # print(slopes)\n",
    "    return slopes\n",
    "\n",
    "    \n",
    "def calc_trend_ca(dir_download, dir_trend):\n",
    "    #  read all ppt data into combined ds\n",
    "    fn = glob.glob(dir_download + '/**/*.bil')\n",
    "    fn.sort()\n",
    "    data = [xr.open_rasterio(f) for f in fn]\n",
    "    combined_ds = xr.concat(data, dim = 'band')\n",
    "\n",
    "    # interpolat the ds as there are missing data\n",
    "    data_array = combined_ds\n",
    "    data_array_interpolated = data_array.interpolate_na(dim='x', method='linear', use_coordinate='x')\n",
    "    data_array_interpolated = data_array_interpolated.interpolate_na(dim='y', method='linear', use_coordinate='y')\n",
    "\n",
    "    # calculate trend based on the interpolated data, this takes about 600s\n",
    "    trend = xr.apply_ufunc(theil_sen_trend, data_array_interpolated, input_core_dims=[['band']], output_core_dims=[[]], vectorize=True)\n",
    "\n",
    "     #plot California data\n",
    "    trend_ca = trend.sel(y = slice(34,42), x = slice(-124, -117))\n",
    "    trend_ca.plot()\n",
    "    trend_ca.to_netcdf(dir_trend)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate trend for CA\n",
    "* Total precipitation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dir_prism = '/Users/kehanyang/Library/CloudStorage/OneDrive-UW/research/pc3_meadow_ph/data/PRISM'\n",
    "variable = 'ppt'\n",
    "years = range(2001, 2023)\n",
    "dir_download = os.path.join(dir_prism, variable+'/annual')\n",
    "\n",
    "# donwload PRISM PPT data \n",
    "download_data(variable, years, dir_prism)\n",
    "unzip_prism(dir_download)\n",
    "\n",
    "dir_trend = './ca_ppt_trend_01_22.nc'\n",
    "calc_trend_ca(dir_download = dir_download, dir_trend = dir_trend)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Mean Temperature "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "variable = 'tmean'\n",
    "years = range(2001, 2023)\n",
    "dir_download = os.path.join(dir_prism, variable+'/annual')\n",
    "\n",
    "# donwload PRISM PPT data \n",
    "download_data(variable, years, dir_prism)\n",
    "unzip_prism(dir_download)\n",
    "\n",
    "dir_trend = './ca_tmean_trend_01_22.nc'\n",
    "calc_trend_ca(dir_download = dir_download, dir_trend = dir_trend)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the mean trend for each meadow extent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install rasterstats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read meadow shapfile \n",
    "import geopandas as gpd \n",
    "import rasterstats\n",
    "shp = gpd.read_file('/Users/kehanyang/Documents/research/pc2_meadows/data/Sierra_meadows/SNMMPC_v2_one_acre_WGS.shp')\n",
    "shp = gpd.read_file('/Users/kehanyang/Documents/research/pc2_meadows/data/Sierra_meadows/meadow_close_to_snotel/Meadow_close_to_SNOTEL.shp')\n",
    "\n",
    "# read trend file using xarray\n",
    "data_trend = xr.open_rasterio('./ca_ppt_trend_01_22.nc')\n",
    "\n",
    "# calcumate the mean value for each polygon using rasterstats\n",
    "stats = rasterstats.zonal.stats(shp, data_trend, stats = 'mean')\n",
    "\n",
    "# Extract the mean values from the statistics.\n",
    "mean_values = [stat['mean'] for stat in stats]\n",
    "\n",
    "# Add the mean values as a new column to the GeoDataFrame.\n",
    "shp['mean_trend_ppt'] = mean_values\n",
    "\n",
    "# Print the GeoDataFrame with the mean values for each polygon.\n",
    "print(gdf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('planet_p36': conda)"
  },
  "interpreter": {
   "hash": "7d941b521942abff02888ea7873cca51c2aac5fb2f3b440dbf15a61d263ddb0d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}