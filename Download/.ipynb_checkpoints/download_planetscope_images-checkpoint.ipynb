{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280a1092-23f1-41f8-b632-442c039d3c2a",
   "metadata": {},
   "source": [
    "### The notebook is used to download planetscope images with custom requiremnets (Kehan Yang, kyang33@uw.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc708a4-c6d0-4f3c-ab46-0a36ce671419",
   "metadata": {},
   "source": [
    "#### Load packages and set up directories\n",
    "Planet has updated its API in March 2023, so some of the functions may not be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b314445e-3631-4ae8-a117-c31c55fbf8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup OK: API key valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyang33/.virtualenvs/planet_project/lib/python3.8/site-packages/planet/api/__init__.py:38: ClientV1DeprecationWarning: The planet.api module is deprecated and will be removed in version 2.0.0. For more details please see the discussion at https://github.com/planetlabs/planet-client-python/discussions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from get_planet import *\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d65faa-e373-4da1-b221-541a4813102a",
   "metadata": {},
   "source": [
    "### Authorize Planet account.\n",
    "You can copy and paste your planet API from your Planet Account setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27767b2c-5e26-49aa-bf17-f1756c65bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're following along with this notebook, you can enter your API Key on the following line, and uncomment it:\n",
    "# os.environ['PLANET_API_KEY']='XX'\n",
    "# Setup the API Key from the `PL_API_KEY` environment variable\n",
    "PLANET_API_KEY = os.getenv('PLANET_API_KEY')\n",
    "\n",
    "#### Get your API Key and run validity check\n",
    "# This gets your API key and prompts you incase your API key is missing or if there are authentication issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4923eba-4b65-4793-928a-6345be739b11",
   "metadata": {},
   "source": [
    "### Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99647d48-8fa1-4435-b24e-a6d62b318c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for the geomtry, the format has to be geojson\n",
    "dir_geom = \"../../../research/pc2_meadows/data/Sierra_meadows/geojson_test/\"\n",
    "\n",
    "dir_root = './'\n",
    "# directory where the images will be downloaded. \n",
    "dir_download = dir_root + 'temp/download/'\n",
    "\n",
    "# directory for the download links and image ids \n",
    "dir_order_url =  dir_root + 'temp/links/'\n",
    "\n",
    "# change the flag if search and/or download data are required.\n",
    "flag_search = False\n",
    "flag_order = True\n",
    "flag_download = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc75a64-c5f9-4781-a732-95ad53e2e46f",
   "metadata": {},
   "source": [
    "### Start to search and/or download data\n",
    "If flag_download is set to False, the order will not be placed, and your quote will not be consumed. The total areas will be saved in a CSV file, allowing you to estimate the total size of the areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e371d08-7778-41ec-8322-a458a942ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the searching period\n",
    "ID_period = [str(i) for i in range(2016,2017)]\n",
    "\n",
    "if flag_search:\n",
    "    for yr in ID_period:\n",
    "        df_search = pd.DataFrame() # save all image ids\n",
    "        \n",
    "        #file to store url -- planet data download links\n",
    "        file_orders = dir_order_url + yr + '.txt'\n",
    "        start_time = yr + '-01-01T00:00:00'\n",
    "        end_time = yr + '-12-02T12:00:00'\n",
    "        \n",
    "        overlap = 99 # at least with 99% overlap \n",
    "        cloud_pct = 0.05 # no more than 5% cloud cover\n",
    "\n",
    "\n",
    "        #search for geojson file\n",
    "        fn = glob.glob(dir_geom + \"*.json\")\n",
    "        ID_shp = [id.split(\"/\")[-1] for id in fn]\n",
    "        df = pd.DataFrame(data = {\n",
    "            \"file\": fn, \n",
    "            \"index\":  [i.split(\"/\")[-1] for i in fn],\n",
    "            \"ID\": [id.split(\"/\")[-1].split('.')[0] for id in fn]\n",
    "            })\n",
    "        df = df.sort_values(\"index\", ascending = True)\n",
    "\n",
    "        print(df.head())\n",
    "\n",
    "    # check whether the order url txt file is exist. if exist, read data; otherwise, creat file.\n",
    "        idx = 0 \n",
    "        if exists(file_orders):\n",
    "            order_urls = pd.read_csv(file_orders)\n",
    "        else:\n",
    "            order_urls = pd.DataFrame(columns = {\"index\",\"ID_geom\", \"order_url\"})\n",
    "\n",
    "\n",
    "        for irow in df.itertuples():\n",
    "\n",
    "        # Search id \n",
    "            print(irow)\n",
    "            ID_geom = irow.ID.split(\".\")[0]+ '_' + yr\n",
    "            print(ID_geom)\n",
    "\n",
    "            if ID_geom not in order_urls.ID_geom.to_list():\n",
    "\n",
    "                print('Searching available images ------- ')\n",
    "                idlist = ft_iterate(item_type='PSScene', # planet has changed the product item type from 'PSScene4Band' with PSScene\n",
    "                        asset_type= 'ortho_analytic_4b',\n",
    "                        geom = read_geom(irow.file),#\".json\"),\n",
    "                        start = start_time,\n",
    "                        end = end_time,\n",
    "                        cloud_cover = cloud_pct, #cloud cover range 0-1 represting 0-100% so 0.5 means max allowed 50% cloud cover\n",
    "                        ovp = overlap) #% minimum % overlap 0-100\n",
    "\n",
    "                idlist['ID_geom'] = ID_geom\n",
    "                print(idlist.shape)\n",
    "                idlist.sort_values(\"date\")\n",
    "                df_search = pd.concat([df_search, idlist])\n",
    "\n",
    "\n",
    "                # print(irow.file)\n",
    "                if(flag_order):\n",
    "                    payload_info = order_payload(Name_download = ID_geom, ID_imgs = idlist.id.values.tolist(), File_geom = irow.file)\n",
    "                    # print(payload_info)\n",
    "                    print(\"Pay order:\".format(),ID_geom)\n",
    "\n",
    "\n",
    "                    order_url = order_now(payload_info) # error response 400  \n",
    "\n",
    "                    order_urls.loc[idx, \"index\"] = idx        \n",
    "                    order_urls.loc[idx, \"ID_geom\"] = ID_geom\n",
    "                    order_urls.loc[idx, \"order_url\"] = order_url\n",
    "                    order_urls.loc[idx, \"NUM\"] = idlist.shape[0]  \n",
    "                    order_urls.loc[idx, \"Total area\"] = sum(idlist['estimated area'])  \n",
    "\n",
    "\n",
    "                    # order_urls.append(order_url)  # save all URLs\n",
    "                    order_urls.to_csv(file_orders, index = None)# save all URLs\n",
    "\n",
    "\n",
    "            idx = idx + 1\n",
    "        df_search.to_csv(dir_order_url+'idlist.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71852940-a8f6-4118-84c2-99b4b641c416",
   "metadata": {},
   "source": [
    "### Start to download data\n",
    "After receiving email notifications, you can use the following code to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93321992-a966-40f2-9eb9-78de641d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read order URL from file_orders\n",
    "flag_download = False\n",
    "if flag_download:\n",
    "    order_urls_read = pd.read_csv(file_orders)\n",
    "\n",
    "    for url in order_urls_read.itertuples():\n",
    "        print(url.order_url)\n",
    "        # if poll_for_success(url.order_url):\n",
    "        if os.path.exists(dir_download + url.ID_geom):\n",
    "            print(\"Data have been downloaded\".format(), dir_download + url.ID_geom)\n",
    "        else:\n",
    "            print(\"start downloading data to\".format(), dir_download + url.ID_geom)\n",
    "            download_results(url.order_url,folder = dir_download + url.ID_geom)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b04de5-ccb4-4da3-997c-7b07874c2867",
   "metadata": {},
   "source": [
    "### Check downloaded data\n",
    "Check the data to determine if it has been downloaded completely. If not, download the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba121ba-4533-4d7c-b98e-06217e152d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether all data have been downloaded \n",
    "# read search csv \n",
    "dir_search = '/Users/kehanyang/Documents/resarch/pc2_meadows/data/planet/orders/Meadows/'\n",
    "fn = glob.glob(dir_search + '*.csv')\n",
    "id_miss = []\n",
    "for i in range(0, len(fn)-1):\n",
    "    data = pd.read_csv(fn[i])\n",
    "    id = os.path.basename(fn[i]).split('.csv')[0]\n",
    "    # print(id)\n",
    "    # print(data[[\"id\",'date','instrument']])\n",
    "    data['id_three'] = [(i.split(\"_\")[0] + '_' +  i.split(\"_\")[1] + '_' + i.split(\"_\")[2]) for i in data['id']]\n",
    "\n",
    "    dir_image = dir_search + id\n",
    "    # print(dir_image)\n",
    "    fn_img = glob.glob(dir_image + '/**/**/*.tif', recursive = True)\n",
    "    fn_img_names = [os.path.basename(f) for f in fn_img]\n",
    "    id_downloaded = [(i.split(\"_\")[0] + '_' +  i.split(\"_\")[1] + '_' + i.split(\"_\")[2]) for i in fn_img_names]\n",
    "\n",
    "    not_downloaded = data[~data['id_three'].isin(id_downloaded)]\n",
    "\n",
    "    if len(not_downloaded) > 0:\n",
    "        print(id)\n",
    "        print(not_downloaded)\n",
    "        id_miss.append(id)\n",
    "\n",
    "id_downloaded\n",
    "not_downloaded, id_downloaded\n",
    "print(len(id_miss))\n",
    "id_miss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet_project",
   "language": "python",
   "name": "planet_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
